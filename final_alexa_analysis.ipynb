{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1832f5ee-0760-4273-96d2-bb3c5954f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Required Libraries \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBRegressor\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Step 2: Read Dataset using pandas\n",
    "df = pd.read_csv('/content/amazon_alexa.tsv', sep='\\t')\n",
    "\n",
    "# Step 3: Data Exploration\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())  # Check for missing values, data types\n",
    "\n",
    "# Handling missing values\n",
    "df = df.dropna()  # Remove rows with missing values\n",
    "print(f\"\\nData after removing missing values: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "# Step 4: Sentiment Analysis (VADER) on 'verified_reviews' column\n",
    "if 'verified_reviews' in df.columns:\n",
    "    sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "    df['sentiment'] = df['verified_reviews'].apply(lambda x: sentiment_analyzer.polarity_scores(x)['compound'])\n",
    "\n",
    "if 'sentiment' in df.columns:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(df['sentiment'], bins=10, kde=True, color='blue')\n",
    "    plt.title('Distribution of Sentiment Scores')\n",
    "    plt.xlabel('Sentiment Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "# Step 5: Custom Stopwords List\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))  # Pre-defined stopwords from NLTK library\n",
    "\n",
    "# Step 6: Clean Feedback Function (Removing Stopwords)\n",
    "def clean_feedback(feedback):\n",
    "    words = feedback.lower().split()\n",
    "    cleaned_words = [word for word in words if word not in stopwords]  # Only keep non-stopwords\n",
    "    return \" \".join(cleaned_words)\n",
    "\n",
    "# Apply cleaning to all feedback text\n",
    "df['cleaned_feedback'] = df['verified_reviews'].apply(clean_feedback)\n",
    "\n",
    "# Step 7: Word Cloud Generation for Different Feedback Categories\n",
    "def generate_wordcloud(feedback_list, title):\n",
    "    wordcloud = WordCloud(background_color='white', stopwords=stopwords, width=800, height=400).generate(\" \".join(feedback_list))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Separate positive and negative feedback\n",
    "positive_feedback = df[df['sentiment'] > 0.05]['cleaned_feedback']\n",
    "negative_feedback = df[df['sentiment'] < -0.05]['cleaned_feedback']\n",
    "all_feedback = df['cleaned_feedback']\n",
    "\n",
    "# Generate word clouds for all, positive, and negative feedback\n",
    "generate_wordcloud(all_feedback, \"Word Cloud of All Customer Feedback (Cleaned)\")\n",
    "generate_wordcloud(positive_feedback, \"Word Cloud of Positive Customer Feedback (Cleaned)\")\n",
    "generate_wordcloud(negative_feedback, \"Word Cloud of Negative Customer Feedback (Cleaned)\")\n",
    "\n",
    "# Step 8: Feature Extraction (TF-IDF) from 'cleaned_feedback' column\n",
    "if 'cleaned_feedback' in df.columns and 'sentiment' in df.columns:\n",
    "    tfidf = TfidfVectorizer(stop_words='english', max_features=500)  # Increased max_features for better accuracy\n",
    "    tfidf_matrix = tfidf.fit_transform(df['cleaned_feedback'])\n",
    "    feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# Step 9: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 10: Hyperparameter Tuning for XGBoost using Randomized Search\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(100, 500, 50),\n",
    "    'max_depth': np.arange(3, 15),\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15],\n",
    "    'min_child_weight': [1, 2, 3]\n",
    "}\n",
    "\n",
    "xgb = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "random_search = RandomizedSearchCV(xgb, param_dist, n_iter=50, cv=3, n_jobs=-1, verbose=2)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 11: Train XGBoost with best parameters\n",
    "best_xgb = random_search.best_estimator_\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Step 12: Make Predictions\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "\n",
    "# Step 13: Calculate Metrics (Mean Squared Error, R² Score)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nMean Squared Error: {mse:.4f}\")\n",
    "print(f\"R² Score (Accuracy): {r2:.4f}\")\n",
    "\n",
    "# Step 14: Feature Importance from XGBoost\n",
    "importance = best_xgb.feature_importances_\n",
    "importance_df = pd.DataFrame({'feature': feature_names, 'importance': importance})\n",
    "importance_df = importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Step 15: Visualize Feature Importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=importance_df, palette='coolwarm')\n",
    "plt.title('Feature Importance in Predicting Customer Sentiment (XGBoost)')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n",
    "\n",
    "# Step 16: Dynamic Insights for Negative Words Only\n",
    "negative_wordcloud_words = \" \".join(negative_feedback)\n",
    "print(\"\\nDynamic Insights Based on Negative Feedback (Using Cleaned Data):\")\n",
    "if 'battery' in negative_wordcloud_words:\n",
    "    print(\"- 'Battery' frequently appears in negative feedback. Consider improving battery life.\")\n",
    "if 'price' in negative_wordcloud_words:\n",
    "    print(\"- 'Price' frequently appears in negative feedback. Reducing price might improve satisfaction.\")\n",
    "if 'privacy' in negative_wordcloud_words:\n",
    "    print(\"- 'Privacy' concerns frequently appear. Addressing privacy issues could help.\")\n",
    "if 'warranty' in negative_wordcloud_words:  # Fixed typo from 'waranty'\n",
    "    print(\"- 'Warranty' concerns frequently appear. Addressing warranty issues could help.\")\n",
    "if 'performance' in negative_wordcloud_words:\n",
    "    print(\"- 'Performance' concerns frequently appear. Addressing performance issues could help.\")\n",
    "if 'speaker' in negative_wordcloud_words:\n",
    "    print(\"- 'Speaker' concerns frequently appear. Addressing speaker quality could help.\")\n",
    "if 'quality' in negative_wordcloud_words:\n",
    "    print(\"- 'Quality' concerns frequently appear. Addressing quality issues could help.\")\n",
    "else:\n",
    "    print(\"- General improvements could be made based on other frequent negative feedback.\")\n",
    "\n",
    "print(\"\\nOverall Conclusion: Focus on addressing negative sentiment around frequent issues to improve product satisfaction.\")\n",
    "\n",
    "# Testing with new reviews\n",
    "test_reviews = [\n",
    "    \"I love the sleek design and the AR functionality is amazing.\",\n",
    "    \"The device is way too expensive for its limited features.\",\n",
    "    \"Battery life is terrible, I can barely use it for a few hours.\",\n",
    "    \"It's a great innovation, but it gets uncomfortable after long use.\",\n",
    "    \"The voice commands are unresponsive and the price is not justified.\",\n",
    "    \"Alexa is working fine.\",\n",
    "    \"It is the worst product.\",\n",
    "    \"It is not user-friendly.\",\n",
    "    \"Need better improvement in build quality.\",\n",
    "    \"I am satisfied with the price and it is justified.\",\n",
    "    \"Alexa's sound quality is not good.\",\n",
    "    \"Alexa responds well and poorly.\",\n",
    "    \"Alexa's warranty is not fair.\"\n",
    "]\n",
    "\n",
    "# Transform new reviews into TF-IDF features\n",
    "test_tfidf = tfidf.transform(test_reviews)\n",
    "\n",
    "# Use the trained model to predict sentiment for new reviews\n",
    "test_pred = best_xgb.predict(test_tfidf)\n",
    "\n",
    "# Step 17: Sentiment Analysis on test reviews\n",
    "for i, review in enumerate(test_reviews):\n",
    "    sentiment = sentiment_analyzer.polarity_scores(review)['compound']\n",
    "    if sentiment >= 0.05:\n",
    "        sentiment_label = \"Positive\"\n",
    "    elif sentiment <= -0.05:\n",
    "        sentiment_label = \"Negative\"\n",
    "    else:\n",
    "        sentiment_label = \"Neutral\"\n",
    "    \n",
    "    print(f\"\\nReview: '{review}'\")\n",
    "    print(f\"Predicted Sentiment Score: {test_pred[i]:.2f}\")\n",
    "    print(f\"Sentiment: {sentiment_label} (Score: {sentiment:.2f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
